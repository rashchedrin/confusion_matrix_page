window.LANGUAGES = {
  en: {
    name: 'English',
    strings: {
      pageTitle: 'Confusion Matrix Viewer',
      pageSubtitle: 'Paste your tab-separated table data and visualize it as a color-coded confusion matrix',
      inputDataTitle: 'Input Data',
      inputPlaceholder: 'Paste your table here (tab or space separated)...\nExample:\nGiraffe\tRhino\tCrab\n360\t12\t24\n4\t200\t2\n100\t60\t3000',
      exampleData: 'Giraffe\tRhino\tCrab\tFox\tAnt\n360\t12\t24\t18\t6\n4\t200\t2\t8\t2\n100\t60\t3000\t600\t1600\n100\t50\t75\t1000\t30\n500\t700\t2000\t1000\t100000',
      generateButton: 'Visualize',
      normalizationTitle: 'Normalization Options',
      normOriginal: 'Original (No normalization)',
      normRow: 'Row normalized',
      normColumn: 'Column normalized',
      normRowColumn: 'Row then column normalized',
      normSinkhorn: 'Sinkhorn-Knopp normalized',
      normSum: 'Sum normalized',
      viewMode: 'View Mode:',
      tableView: 'Table View',
      tabSeparatedText: 'Tab-separated Text',
      downloadCSV: 'Download as CSV',
      includeRowColumnSums: 'Include row/column sums',
      includeAnswerInfo: 'Include answer information',
      additiveSmoothing: 'Additive smoothing',
      predictedLabel: 'Predicted →',
      actualLabel: 'Actual ↓',
      sumLabel: 'Sum',
      answerInfoLabel: 'Answer Info (bits)',
      matrixTitle: 'Confusion Matrix',
      stats: {
        dimensions: 'Dimensions',
        dimensionsTip: 'Matrix size (rows × columns)',
        min: 'Min Value',
        minTip: 'Smallest value in the matrix',
        max: 'Max Value',
        maxTip: 'Largest value in the matrix',
        mean: 'Mean Value',
        meanTip: 'Average of all matrix values',
        trace: 'Trace',
        traceTip: 'Sum of diagonal elements (correctly classified instances)',
        tracePerClass: 'Trace/n_classes',
        tracePerClassTip: 'Average accuracy per class (trace divided by number of classes)',
        mi: 'Mutual Information',
        miTip: 'MI = ∑∑ P(x,y) × log₂(P(x,y) / (P(x)×P(y))) - dependence between predicted and actual classes (bits)',
        nmi: 'Normalized MI',
        nmiTip: 'NMI = MI / √(H(X) × H(Y)) - geometric mean normalization, range [0,1]'
      },
      normalizationNames: {
        none: 'Original',
        row: 'Row Normalized',
        column: 'Column Normalized',
        row_then_column: 'Row → Column Normalized',
        sinkhorn_knopp: 'Sinkhorn-Knopp Normalized',
        sum: 'Sum Normalized'
      },
      tooltips: {
        original: 'Original confusion matrix showing raw counts or frequencies.\n\nInterpretation:\n• Each cell [i,j] = number of instances where true class was i and predicted class was j\n• Row sums = total instances per true class\n• Column sums = total instances per predicted class\n• Diagonal elements = correctly classified instances\n• Off-diagonal elements = misclassifications\n\nUse when: You want to see absolute numbers and class imbalances.',
        rowNorm: 'Row-normalized matrix showing conditional probabilities P(Predicted | True).\n\nInterpretation:\n• Each cell [i,j] = probability of predicting class j given true class i\n• Each row sums to 1.0 (probability distribution)\n• Diagonal elements = per-class recall (sensitivity)\n• Off-diagonal elements = per-class confusion rates\n• Removes class imbalance effects\n\nUse when: You want to analyze classifier performance per true class, compare recall across classes, or when classes have different frequencies.\n\nExample: Cell [Cat, Dog] = 0.15 means 15% of cats were misclassified as dogs.',
        columnNorm: 'Column-normalized matrix showing conditional probabilities P(True | Predicted).\n\nInterpretation:\n• Each cell [i,j] = probability that true class is i given prediction j\n• Each column sums to 1.0 (probability distribution)\n• Diagonal elements = per-class precision (positive predictive value)\n• Off-diagonal elements = per-prediction confusion rates\n• Shows reliability of predictions\n\nIMPORTANT: These are true posterior probabilities P(True | Predicted) ONLY if the test samples come from the same distribution as the data used to create this confusion matrix.\n\nUse when: You want to analyze prediction reliability under the assumption that future data matches current test distribution.\n\nExample: Cell [Cat, Dog] = 0.20 means 20% of \u2018Dog\u2019 predictions were actually cats (in this dataset).',
        rowColumnNorm: 'Sequential normalization: first by rows, then by columns.\n\nInterpretation:\n• Step 1: Row normalization creates P(Predicted | True)\n• Step 2: Column normalization creates posterior probabilities P(True | Predicted) under uniform prior\n• Columns sum to 1.0 (posterior probability distributions)\n• Rows do not sum to 1.0 (balanced by uniform prior assumption)\n• Represents Bayesian inference assuming equal class priors\n\nUse when: You want posterior probabilities assuming uniform class distribution, remove original class frequency bias, or analyze classifier output under balanced prior assumptions.\n\nBayesian interpretation: Converts classifier outputs to posterior probabilities assuming P(True class) is uniform across all classes.',
        sinkhornNorm: 'Doubly stochastic matrix via iterative Sinkhorn-Knopp algorithm.\n\nInterpretation:\n• Each row AND each column sums to 1.0 simultaneously\n• Creates a balanced joint probability distribution P(True, Predicted)\n• Preserves relative confusion patterns while removing all bias\n• Converges to optimal transport solution\n• Matrix may not be symmetric (asymmetry has meaning)\n\nUse when: You want to analyze pure confusion patterns without any class frequency or prediction bias effects, study classifier behavior in idealized balanced scenarios.\n\nMathematical: Finds row scaling r and column scaling c such that diag(r) × Original × diag(c) is doubly stochastic.\n\nAsymmetry interpretation: Reflects inherent directional confusion patterns between classes.',
        sumNorm: 'Matrix normalized by total sum, creating a joint probability distribution.\n\nInterpretation:\n• Each cell [i,j] = P(True=i AND Predicted=j)\n• All cells sum to 1.0 (complete probability space)\n• Diagonal elements = P(correct classification)\n• Off-diagonal elements = P(specific misclassification types)\n• Preserves original class frequency information\n\nUse when: You want to analyze the overall probability distribution of classification outcomes, study the likelihood of specific confusion types, or maintain class frequency relationships.\n\nExample: Cell [Cat, Dog] = 0.05 means 5% of all classifications are \u2018cats predicted as dogs\u2019.',
        smoothingToggle: 'Additive smoothing (Laplace smoothing) adds pseudocounts to handle zero probabilities and improve estimates:\n\n• Essential for epistemologically correct probabilities estimation\n• Prevents division by zero in probability calculations\n• Provides more robust statistical estimates\n• Essential for reliable mutual information computation\n• Recommended for sparse confusion matrices\n\nThe α parameter controls the amount of smoothing applied.',
        alphaParam: 'Alpha parameter (pseudocounts added to each cell):\n\nα = 0.5 (Jeffrey\u2019s Prior - RECOMMENDED):\n• Non-informative Bayesian prior for Dirichlet distribution\n• Scale-invariant and transformation-invariant\n• Minimal bias while handling zero counts\n• Theoretically optimal for unknown distributions\n\nα = 1.0 (Laplace\u2019s Rule of Succession):\n• Uniform prior assuming all outcomes equally likely\n• Classic approach, easy to interpret\n• Good when no prior knowledge exists\n• Adds exactly 1 pseudocount per cell\n\nα = 0 (No smoothing):\n• Uses original counts without modification\n• May cause issues with zero entries\n\nHigher α values = more smoothing = more conservative estimates',
        rasTitle: 'RAS Decomposition (Row And column Scaling)',
        rasTooltip: 'RAS Decomposition: DoublyStochastic = diag(r) × Original × diag(c)',
        rowScalingFactors: 'Row Scaling Factors (r)',
        columnScalingFactors: 'Column Scaling Factors (c)',
        reconstructionFormula: 'Reconstruction: Original[i,j] = DoublyStochastic[i,j] / (r[i] × c[j])',
        reconstructionTooltip: 'To reconstruct original matrix: divide doubly stochastic by both r[i] and c[j]',
        answerInfo: 'The amount of information provided by the classifier\'s answer (in bits). Higher = more informative; 0 bits = no information.'
      }
    }
  },
  ru: {
    name: 'Русский',
    strings: {
      pageTitle: 'Визуализатор матриц ошибок',
      pageSubtitle: 'Вставьте таблицу и визуализируйте её как матрицу ошибок с цветовой заливкой',
      inputDataTitle: 'Входные данные',
      inputPlaceholder: 'Вставьте сюда таблицу (разделители — табы или пробелы)...\nПример:\nЖираф\tНосорог\tКраб\n360\t12\t24\n4\t200\t2\n100\t60\t3000',
      exampleData: 'Жираф\tНосорог\tКраб\tЛиса\tМуравей\n360\t12\t24\t18\t6\n4\t200\t2\t8\t2\n100\t60\t3000\t600\t1600\n100\t50\t75\t1000\t30\n500\t700\t2000\t1000\t100000',
      generateButton: 'Визуализировать',
      normalizationTitle: 'Опции нормализации',
      normOriginal: 'Оригинальная (без нормализации)',
      normRow: 'Нормализация по строкам',
      normColumn: 'Нормализация по столбцам',
      normRowColumn: 'Сначала по строкам, затем по столбцам',
      normSinkhorn: 'Нормализация Синкхорна-Кноппа',
      normSum: 'Нормализация по сумме',
      viewMode: 'Режим просмотра:',
      tableView: 'Таблица',
      tabSeparatedText: 'Текст (табами)',
      downloadCSV: 'Скачать CSV',
      includeRowColumnSums: 'Показывать суммы по строкам/столбцам',
      includeAnswerInfo: 'Показывать информацию ответа',
      additiveSmoothing: 'Аддитивное сглаживание',
      predictedLabel: 'Предсказанный →',
      actualLabel: 'Истинный ↓',
      sumLabel: 'Сумма',
      answerInfoLabel: 'Информация ответа (в битах)',
      matrixTitle: 'Матрица ошибок',
      stats: {
        dimensions: 'Размерность',
        dimensionsTip: 'Размер матрицы (строки × столбцы)',
        min: 'Минимум',
        minTip: 'Минимальное значение в матрице',
        max: 'Максимум',
        maxTip: 'Максимальное значение в матрице',
        mean: 'Среднее',
        meanTip: 'Среднее всех значений матрицы',
        trace: 'След (Trace)',
        traceTip: 'Сумма диагональных элементов (верные классификации)',
        tracePerClass: 'След/число_классов',
        tracePerClassTip: 'Средняя точность по классам (след / число классов)',
        mi: 'Взаимная информация',
        miTip: 'MI = ∑∑ P(x,y) × log₂(P(x,y) / (P(x)×P(y))) — зависимость между истинными и предсказанными классами (в битах)',
        nmi: 'Нормированная MI',
        nmiTip: 'NMI = MI / √(H(X) × H(Y)) — нормализация геометрическим средним, диапазон [0,1]'
      },
      normalizationNames: {
        none: 'Оригинальная',
        row: 'Норм. по строкам',
        column: 'Норм. по столбцам',
        row_then_column: 'Строки → Столбцы',
        sinkhorn_knopp: 'Синкхорн-Кнопп',
        sum: 'Норм. по сумме'
      },
      tooltips: {
        original: 'Оригинальная матрица с сырыми счетчиками/частотами.\n\nИнтерпретация:\n• Ячейка [i,j] = сколько раз истинный класс i был предсказан как j\n• Суммы по строкам = объектов в истинном классе\n• Суммы по столбцам = предсказаний данного класса\n• Диагональ = верные классификации\n• Вне диагонали = ошибки\n\nКогда использовать: нужно видеть абсолютные числа и дисбаланс классов.',
        rowNorm: 'Нормализация по строкам: условные вероятности P(Предсказан | Истинный).\n\nИнтерпретация:\n• [i,j] = вероятность предсказать класс j при истинном i\n• Каждая строка суммируется к 1.0\n• Диагональ = полнота (recall) по классам\n• Вне диагонали = частоты путаницы\n• Убирает влияние дисбаланса классов\n\nКогда использовать: анализ качества по истинным классам, сравнение полноты, разные частоты классов.\n\nПример: [Кот, Пёс] = 0.15 значит 15% котов предсказаны как псы.',
        columnNorm: 'Нормализация по столбцам: условные вероятности P(Истинный | Предсказан).\n\nИнтерпретация:\n• [i,j] = вероятность, что истинный класс i при предсказании j\n• Каждый столбец суммируется к 1.0\n• Диагональ = точность (precision) по классам\n• Вне диагонали = частоты путаницы для предсказаний\n• Показывает надёжность предсказаний\n\nВАЖНО: Это истинные апостериорные вероятности P(Истинный | Предсказан) ТОЛЬКО если выборка из того же распределения, что и данные для этой матрицы ошибок.\n\nКогда использовать: анализ надёжности предсказаний при предположении совпадения распределения будущих данных с текущим тестом.\n\nПример: [Кот, Пёс] = 0.20 значит 20% предсказаний «Пёс» на самом деле коты (в данном наборе).',
        rowColumnNorm: 'Последовательная нормализация: сначала строки, затем столбцы.\n\nИнтерпретация:\n• Шаг 1: по строкам — P(Предсказан | Истинный)\n• Шаг 2: по столбцам — апостериорные P(Истинный | Предсказан) при равномерном априори\n• Столбцы суммируются к 1.0\n• Строки не суммируются к 1.0 (балансируются равномерным априори)\n• Соответствует байесовскому выводу при равных априорных вероятностях классов\n\nКогда использовать: нужны постериорные вероятности при равномерном априори, устранение влияния исходной частоты классов.\n\nБайесовская интерпретация: переводит выходы классификатора в постериорные вероятности при равномерном P(Истинный класс).',
        sinkhornNorm: 'Дважды стохастическая матрица (алгоритм Синкхорна-Кноппа).\n\nИнтерпретация:\n• И строки, и столбцы суммируются к 1.0\n• Сбалансированное совместное распределение P(Истинный, Предсказан)\n• Сохраняет относительные шаблоны путаницы, убирая смещения\n• Сходится к решению оптимальной транспортировки\n• Матрица может быть несимметричной (асимметрия имеет смысл)\n\nКогда использовать: анализ чистых шаблонов путаницы без влияния частот и смещений.\n\nМатематически: ищет масштабирования r и c, такие что diag(r) × Original × diag(c) — дважды стохастическая.',
        sumNorm: 'Нормализация по общей сумме — совместное распределение.\n\nИнтерпретация:\n• [i,j] = P(Истинный=i И Предсказан=j)\n• Сумма всех ячеек = 1.0\n• Диагональ = P(верная классификация)\n• Вне диагонали = P(конкретные типы ошибок)\n• Сохраняет информацию о частотах классов\n\nКогда использовать: изучение общей структуры вероятностей исходов классификации.\n\nПример: [Кот, Пёс] = 0.05 — 5% всех классификаций это «коты как псы».',
        smoothingToggle: 'Аддитивное сглаживание (Лапласа) добавляет псевдосчёты, чтобы избежать нулевых вероятностей и улучшить оценки:\n\n• Необходимо для эпистемологически корректной оценки вероятностей\n• Избегает деления на ноль в вероятностных расчётах\n• Даёт более устойчивые оценки\n• Важно для корректного расчёта взаимной информации\n• Рекомендуется при разреженных матрицах\n\nПараметр α управляет силой сглаживания.',
        alphaParam: 'Параметр α (псевдосчёты в каждую ячейку):\n\nα = 0.5 (априори Джеффриза — РЕКОМЕНДУЕТСЯ):\n• Неинформативный байесовский априор для Дирихле\n• Инвариантен к масштабу и преобразованиям\n• Минимальное смещение при обработке нулей\n• Теоретически оптимален при неизвестном распределении\n\nα = 1.0 (правило Лапласа):\n• Равномерное априори (все исходы равновероятны)\n• Классический подход, легко интерпретируется\n• Хорош при отсутствии априорных знаний\n• Ровно 1 псевдосчёт в каждую ячейку\n\nα = 0 (без сглаживания):\n• Используются исходные счёты\n• Возможны проблемы с нулями\n\nБольше α = сильнее сглаживание = более консервативные оценки',
        rasTitle: 'Декомпозиция RAS (масштабирование строк и столбцов)',
        rasTooltip: 'Декомпозиция RAS: DoublyStochastic = diag(r) × Original × diag(c)',
        rowScalingFactors: 'Коэффициенты масштабирования строк (r)',
        columnScalingFactors: 'Коэффициенты масштабирования столбцов (c)',
        reconstructionFormula: 'Восстановление: Original[i,j] = DoublyStochastic[i,j] / (r[i] × c[j])',
        reconstructionTooltip: 'Для восстановления исходной матрицы: разделить дважды стохастическую матрицу на r[i] и c[j]',
        answerInfo: 'Количество информации, которую даёт ответ классификатора (в битах). Больше — информативнее; 0 бит — нет информации.'
      }
    }
  }
};
