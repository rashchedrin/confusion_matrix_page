window.LANGUAGES = {
  en: {
    name: 'English',
    strings: {
      pageTitle: 'Confusion Matrix Viewer',
      pageSubtitle: 'Paste your tab-separated table data and visualize it as a color-coded confusion matrix',
      inputDataTitle: 'Input Data',
      inputPlaceholder: 'Paste your table here (tab or space separated)...\nExample:\nGiraffe\tRhino\tCrab\n360\t12\t24\n4\t200\t2\n100\t60\t3000',
      exampleData: 'Giraffe\tRhino\tCrab\tFox\tAnt\n360\t12\t24\t18\t6\n2\t240\t0\t4\t2\n100\t40\t3000\t600\t1600\n100\t50\t75\t1000\t30\n500\t10\t2000\t1000\t100000',
      templateLabel: 'Template:',
      templates: {
        multiclass: 'Multi-class classifier',
        allPositive: 'All positive (noninformative)',
        onePercentPositive: '1% positive (noninformative)'
      },
      templateData: {
        multiclass: 'Giraffe\tRhino\tCrab\tFox\tAnt\n360\t12\t24\t18\t6\n2\t240\t0\t4\t2\n100\t40\t3000\t600\t1600\n100\t50\t75\t1000\t30\n500\t10\t2000\t1000\t100000',
        allPositive: 'Positive\tNegative\n950\t0\n50\t0',
        onePercentPositive: 'Positive\tNegative\n2000\t20\n100\t1'
      },
      generateButton: 'Visualize',
      normalizationTitle: 'Normalization Options',
      normOriginal: 'Original (No normalization)',
      normRow: 'Normalized by truth (rows)',
      normColumn: 'Normalized by prediction (columns)',
      normRowColumn: 'Truth then prediction normalized',
      normSinkhorn: 'Sinkhorn-Knopp normalized',
      normSum: 'Sum normalized',
      normPrior: 'Prior normalized',
      normPriorThenColumn: 'Prior then prediction normalized',
      viewMode: 'View Mode:',
      tableView: 'Table',
      tabSeparatedText: 'Text',
      downloadCSV: 'Download as CSV',
      includeRowColumnSums: 'Include row/column sums',
      includeAnswerInfo: 'Include answer information',
      additiveSmoothing: 'Additive smoothing',
      predictedLabel: 'Predicted →',
      actualLabel: 'Actual ↓',
      sumLabel: 'Sum',
      answerInfoLabel: 'Answer Info (bits)',
      matrixTitle: 'Confusion Matrix',
      stats: {
        dimensions: 'Dimensions',
        dimensionsTip: 'Matrix size (rows × columns)',
        min: 'Min Value',
        minTip: 'Smallest value in the matrix',
        max: 'Max Value',
        maxTip: 'Largest value in the matrix',
        mean: 'Mean Value',
        meanTip: 'Average of all matrix values',
        trace: 'Trace',
        traceTip: 'Sum of diagonal elements (correctly classified instances)',
        tracePerClass: 'Trace/n_classes',
        tracePerClassTip: 'Average accuracy per class (trace divided by number of classes)',
        minDiagonal: 'Min Diagonal',
        minDiagonalTip: 'Minimum value on the diagonal (worst class performance).\n\nWhen normalized by truth (rows): this is the recall (sensitivity) for the worst-performing class.\n\nWhen normalized by prediction (columns): this is the precision for the worst-performing class.',
        mi: 'Mutual Information',
        miTip: 'Expected information gained from classifier answers.\nFormula: MI = ∑_j P(Pred=j) × [ ∑_i P(True=i | Pred=j) × log₂( P(True=i | Pred=j) / P(True=i) ) ] (bits)',
        nmi: 'Normalized MI',
        nmiTip: 'NMI = MI / √(H(X) × H(Y)) - geometric mean normalization, range [0,1]'
      },
      normalizationNames: {
        none: 'Original',
        row: 'By Truth (Rows)',
        column: 'By Prediction (Columns)',
        row_then_column: 'Truth → Prediction',
        sinkhorn_knopp: 'Sinkhorn-Knopp Normalized',
        sum: 'Sum Normalized',
        prior: 'Prior Normalized',
        prior_then_column: 'Prior → Prediction'
      },
      tooltips: {
        original: 'Original confusion matrix showing raw counts or frequencies.\n\nInterpretation:\n• Each cell [i,j] = number of instances where true class was i and predicted class was j\n• Row sums = total instances per true class\n• Column sums = total instances per predicted class\n• Diagonal elements = correctly classified instances\n• Off-diagonal elements = misclassifications\n\nUse when: You want to see absolute numbers and class imbalances.',
        rowNorm: 'Row-normalized matrix showing conditional probabilities P(Predicted | True).\n\nInterpretation:\n• Each cell [i,j] = probability of predicting class j given true class i\n• Each row sums to 1.0 (probability distribution)\n• Diagonal elements = per-class recall (sensitivity)\n• Off-diagonal elements = per-class confusion rates\n• Removes class imbalance effects\n\nUse when: You want to analyze classifier performance per true class, compare recall across classes, or when classes have different frequencies.\n\nExample: Cell [Cat, Dog] = 0.15 means 15% of cats were misclassified as dogs.',
        columnNorm: 'Column-normalized matrix showing conditional probabilities P(True | Predicted).\n\nInterpretation:\n• Each cell [i,j] = probability that true class is i given prediction j\n• Each column sums to 1.0 (probability distribution)\n• Diagonal elements = per-class precision (positive predictive value)\n• Off-diagonal elements = per-prediction confusion rates\n• Shows reliability of predictions\n\nIMPORTANT: These are true posterior probabilities P(True | Predicted) ONLY if the test samples come from the same distribution as the data used to create this confusion matrix.\n\nUse when: You want to analyze prediction reliability under the assumption that future data matches current test distribution.\n\nExample: Cell [Cat, Dog] = 0.20 means 20% of ‘Dog’ predictions were actually cats (in this dataset).',
        rowColumnNorm: 'Sequential normalization: first by truth (rows), then by prediction (columns).\n\nInterpretation:\n• Step 1: Row normalization creates P(Predicted | True)\n• Step 2: Column normalization creates posterior probabilities P(True | Predicted) under uniform prior\n• Columns sum to 1.0 (posterior probability distributions)\n• Rows do not sum to 1.0 (balanced by uniform prior assumption)\n• Represents Bayesian inference assuming equal class priors\n\nUse when: You want posterior probabilities assuming uniform class distribution, remove original class frequency bias, or analyze classifier output under balanced prior assumptions.\n\nBayesian interpretation: Converts classifier outputs to posterior probabilities assuming P(True class) is uniform across all classes.',
        sinkhornNorm: 'Doubly stochastic matrix via iterative Sinkhorn-Knopp algorithm.\n\nInterpretation:\n• Each row AND each column sums to 1.0 simultaneously\n• Creates a balanced joint probability distribution P(True, Predicted)\n• Preserves relative confusion patterns while removing all bias\n• Converges to optimal transport solution\n• Matrix may not be symmetric (asymmetry has meaning)\n\nUse when: You want to analyze pure confusion patterns without any class frequency or prediction bias effects, study classifier behavior in idealized balanced scenarios.\n\nMathematical: Finds row scaling r and column scaling c such that diag(r) × Original × diag(c) is doubly stochastic.\n\nAsymmetry interpretation: Reflects inherent directional confusion patterns between classes.',
        sumNorm: 'Matrix normalized by total sum, creating a joint probability distribution.\n\nInterpretation:\n• Each cell [i,j] = P(True=i AND Predicted=j)\n• All cells sum to 1.0 (complete probability space)\n• Diagonal elements = P(correct classification)\n• Off-diagonal elements = P(specific misclassification types)\n• Preserves original class frequency information\n\nUse when: You want to analyze the overall probability distribution of classification outcomes, study the likelihood of specific confusion types, or maintain class frequency relationships.\n\nExample: Cell [Cat, Dog] = 0.05 means 5% of all classifications are \'cats predicted as dogs\'.',
        priorNorm: 'Prior-normalized matrix: truth-normalized (rows) multiplied by prior frequencies.\n\nInterpretation:\n• Step 1: Row normalization creates P(Predicted | True)\n• Step 2: Each row multiplied by corresponding prior frequency P(True=i)\n• Result: P(Predicted | True) × P(True) = P(Predicted AND True) with specified priors\n• Rows sum to prior frequencies (not 1.0)\n• Columns sum to P(Predicted) under specified priors\n\nUse when: You want to see confusion matrix under specific prior class distribution assumptions, or analyze classifier performance with custom class frequencies.\n\nBayesian interpretation: Shows joint distribution P(True, Predicted) assuming specified prior P(True).',
        priorThenColumnNorm: 'Prior then prediction normalized: truth-normalized (rows) multiplied by prior frequencies, then column-normalized.\n\nInterpretation:\n• Step 1: Row normalization creates P(Predicted | True)\n• Step 2: Each row multiplied by corresponding prior frequency P(True=i)\n• Step 3: Column normalization creates posterior probabilities P(True | Predicted) under specified prior\n• Columns sum to 1.0 (posterior probability distributions)\n• Rows do not sum to 1.0 (balanced by specified prior assumption)\n• Represents Bayesian inference with custom class priors\n\nUse when: You want posterior probabilities assuming specified class distribution, remove original class frequency bias, or analyze classifier output under custom prior assumptions.\n\nBayesian interpretation: Converts classifier outputs to posterior probabilities assuming P(True class) matches specified priors.',
        smoothingToggle: 'Additive smoothing (Laplace smoothing) adds pseudocounts to handle zero probabilities and improve estimates:\n\n• Essential for epistemologically correct probabilities estimation\n• Prevents division by zero in probability calculations\n• Provides more robust statistical estimates\n• Essential for reliable mutual information computation\n• Recommended for sparse confusion matrices\n\nThe α parameter controls the amount of smoothing applied.',
        alphaParam: 'Alpha parameter (pseudocounts added to each cell):\n\nα = 0.5 (Jeffrey\'s Prior - RECOMMENDED):\n• Non-informative Bayesian prior for Dirichlet distribution\n• Scale-invariant and transformation-invariant\n• Minimal bias while handling zero counts\n• Theoretically optimal for unknown distributions\n\nα = 1.0 (Laplace\'s Rule of Succession):\n• Uniform prior assuming all outcomes equally likely\n• Classic approach, easy to interpret\n• Good when no prior knowledge exists\n• Adds exactly 1 pseudocount per cell\n\nα = 0 (No smoothing):\n• Uses original counts without modification\n• May cause issues with zero entries\n\nHigher α values = more smoothing = more conservative estimates',
        smoothingTypeUniform: 'Uniform',
        smoothingTypeHierarchical: 'Hierarchical',
        hierarchicalSmoothing: 'Hierarchical prior-aware smoothing:\n\nPseudocount[i,j] = k × prior_π_i × prediction_π_j\n\n• Structured pseudocounts based on marginal distributions\n• Represents prior belief that classifier is noninformative\n• More pseudocounts for common class pairs\n• Fewer pseudocounts for rare class pairs\n• k controls total pseudocount mass\n\nStatistical interpretation: Prior belief is the independence model (predictions independent of truth).',
        kParam: 'k parameter (total pseudocount mass):\n\nk = 0.5 (RECOMMENDED):\n• Similar to Jeffrey\'s prior in total mass\n• Distributed according to marginals\n\nHigher k = stronger prior toward independence model',
        rasTitle: 'RAS Decomposition (Row And column Scaling)',
        rasTooltip: 'RAS Decomposition: DoublyStochastic = diag(r) × Original × diag(c)',
        rowScalingFactors: 'Row Scaling Factors (r)',
        columnScalingFactors: 'Column Scaling Factors (c)',
        reconstructionFormula: 'Reconstruction: Original[i,j] = DoublyStochastic[i,j] / (r[i] × c[j])',
        reconstructionTooltip: 'To reconstruct original matrix: divide doubly stochastic by both r[i] and c[j]',
        answerInfo: 'The amount of information provided by the classifier\'s answer (in bits). Higher = more informative; 0 bits = no information.',
        answerInfoMethod: 'Calculation method:\nFor each predicted class j:\nI(True; Predicted=j) = ∑ P(True=i | Predicted=j) × log₂( P(True=i | Predicted=j) / P(True=i) )\nHere P(True=i) is the prior (row marginal), estimated from the confusion matrix (with smoothing if enabled). Units: bits.',
        answerInfoMaxMethod: 'Max method:\nI_max = max_Q D_KL(Q || P(True)) = log₂(1 / min_i P(True=i)).\nWe estimate P(True) from row marginals (with smoothing if enabled). If some prior is 0, I_max = ∞.',
        answerInfoMaxPrefix: 'Theoretical maximum: ',
        maxShortPrefix: 'max: ',
        bitsWord: 'bits'
      }
    }
  },
  ru: {
    name: 'Русский',
    strings: {
      pageTitle: 'Визуализатор матриц ошибок',
      pageSubtitle: 'Вставьте таблицу и визуализируйте её как матрицу ошибок с цветовой заливкой',
      inputDataTitle: 'Входные данные',
      inputPlaceholder: 'Вставьте сюда таблицу (разделители — табы или пробелы)...\nПример:\nЖираф\tНосорог\tКраб\n360\t12\t24\n4\t200\t2\n100\t60\t3000',
      exampleData: 'Жираф\tНосорог\tКраб\tЛиса\tМуравей\n360\t12\t24\t18\t6\n2\t240\t0\t4\t2\n100\t40\t3000\t600\t1600\n100\t50\t75\t1000\t30\n500\t10\t2000\t1000\t100000',
      templateLabel: 'Шаблон:',
      templates: {
        multiclass: 'Многоклассовый классификатор',
        allPositive: 'Все положительные (неинформативный)',
        onePercentPositive: '1% положительных (неинформативный)'
      },
      templateData: {
        multiclass: 'Жираф\tНосорог\tКраб\tЛиса\tМуравей\n360\t12\t24\t18\t6\n2\t240\t0\t4\t2\n100\t40\t3000\t600\t1600\n100\t50\t75\t1000\t30\n500\t10\t2000\t1000\t100000',
        allPositive: 'Положительный\tОтрицательный\n950\t0\n50\t0',
        onePercentPositive: 'Положительный\tОтрицательный\n2000\t20\n100\t1'
      },
      generateButton: 'Визуализировать',
      normalizationTitle: 'Опции нормализации',
      normOriginal: 'Оригинальная (без нормализации)',
      normRow: 'Нормализация по истине (строки)',
      normColumn: 'Нормализация по предсказанию (столбцы)',
      normRowColumn: 'Сначала по истине, затем по предсказанию',
      normSinkhorn: 'Нормализация Синкхорна-Кноппа',
      normSum: 'Нормализация по сумме',
      normPrior: 'Нормализация по априори',
      normPriorThenColumn: 'Априори затем предсказание',
      viewMode: 'Режим просмотра:',
      tableView: 'Таблица',
      tabSeparatedText: 'Текст',
      downloadCSV: 'Скачать CSV',
      includeRowColumnSums: 'Показывать суммы по строкам/столбцам',
      includeAnswerInfo: 'Показывать информацию ответа',
      additiveSmoothing: 'Аддитивное сглаживание',
      predictedLabel: 'Предсказанный →',
      actualLabel: 'Истинный ↓',
      sumLabel: 'Сумма',
      answerInfoLabel: 'Информация ответа (в битах)',
      matrixTitle: 'Матрица ошибок',
      stats: {
        dimensions: 'Размерность',
        dimensionsTip: 'Размер матрицы (строки × столбцы)',
        min: 'Минимум',
        minTip: 'Минимальное значение в матрице',
        max: 'Максимум',
        maxTip: 'Максимальное значение в матрице',
        mean: 'Среднее',
        meanTip: 'Среднее всех значений матрицы',
        trace: 'След (Trace)',
        traceTip: 'Сумма диагональных элементов (верные классификации)',
        tracePerClass: 'След/число_классов',
        tracePerClassTip: 'Средняя точность по классам (след / число классов)',
        minDiagonal: 'Мин. на диагонали',
        minDiagonalTip: 'Минимальное значение на диагонали (худший класс).\n\nПри нормализации по истине (строкам): это полнота (recall) для худшего класса.\n\nПри нормализации по предсказанию (столбцам): это точность (precision) для худшего класса.',
        mi: 'Взаимная информация',
        miTip: 'Математическое ожидание информации, получаемой от ответов классификатора.\nФормула: MI = ∑_j P(Предсказан=j) × [ ∑_i P(Истинный=i | Предсказан=j) × log₂( P(Истинный=i | Предсказан=j) / P(Истинный=i) ) ] (в битах)',
        nmi: 'Нормированная MI',
        nmiTip: 'NMI = MI / √(H(X) × H(Y)) — нормализация геометрическим средним, диапазон [0,1]'
      },
      normalizationNames: {
        none: 'Оригинальная',
        row: 'По истине (строки)',
        column: 'По предсказанию (столбцы)',
        row_then_column: 'Истина → Предсказание',
        sinkhorn_knopp: 'Синкхорн-Кнопп',
        sum: 'Норм. по сумме',
        prior: 'Норм. по априори',
        prior_then_column: 'Априори → Предсказание'
      },
      tooltips: {
        original: 'Оригинальная матрица с сырыми счетчиками/частотами.\n\nИнтерпретация:\n• Ячейка [i,j] = сколько раз истинный класс i был предсказан как j\n• Суммы по строкам = объектов в истинном классе\n• Суммы по столбцам = предсказаний данного класса\n• Диагональ = верные классификации\n• Вне диагонали = ошибки\n\nКогда использовать: нужно видеть абсолютные числа и дисбаланс классов.',
        rowNorm: 'Нормализация по строкам: условные вероятности P(Предсказан | Истинный).\n\nИнтерпретация:\n• [i,j] = вероятность предсказать класс j при истинном i\n• Каждая строка суммируется к 1.0\n• Диагональ = полнота (recall) по классам\n• Вне диагонали = частоты путаницы\n• Убирает влияние дисбаланса классов\n\nКогда использовать: анализ качества по истинным классам, сравнение полноты, разные частоты классов.\n\nПример: [Кот, Пёс] = 0.15 значит 15% котов предсказаны как псы.',
        columnNorm: 'Нормализация по столбцам: условные вероятности P(Истинный | Предсказан).\n\nИнтерпретация:\n• [i,j] = вероятность, что истинный класс i при предсказании j\n• Каждый столбец суммируется к 1.0\n• Диагональ = точность (precision) по классам\n• Вне диагонали = частоты путаницы для предсказаний\n• Показывает надёжность предсказаний\n\nВАЖНО: Это истинные апостериорные вероятности P(Истинный | Предсказан) ТОЛЬКО если выборка из того же распределения, что и данные для этой матрицы ошибок.\n\nКогда использовать: анализ надёжности предсказаний при предположении совпадения распределения будущих данных с текущим тестом.\n\nПример: [Кот, Пёс] = 0.20 значит 20% предсказаний «Пёс» на самом деле коты (в данном наборе).',
        rowColumnNorm: 'Последовательная нормализация: сначала по истине (строки), затем по предсказанию (столбцы).\n\nИнтерпретация:\n• Шаг 1: по строкам — P(Предсказан | Истинный)\n• Шаг 2: по столбцам — апостериорные P(Истинный | Предсказан) при равномерном априори\n• Столбцы суммируются к 1.0\n• Строки не суммируются к 1.0 (балансируются равномерным априори)\n• Соответствует байесовскому выводу при равных априорных вероятностях классов\n\nКогда использовать: нужны постериорные вероятности при равномерном априори, устранение влияния исходной частоты классов.\n\nБайесовская интерпретация: переводит выходы классификатора в постериорные вероятности при равномерном P(Истинный класс).',
        sinkhornNorm: 'Дважды стохастическая матрица (алгоритм Синкхорна-Кноппа).\n\nИнтерпретация:\n• И строки, и столбцы суммируются к 1.0\n• Сбалансированное совместное распределение P(Истинный, Предсказан)\n• Сохраняет относительные шаблоны путаницы, убирая смещения\n• Сходится к решению оптимальной транспортировки\n• Матрица может быть несимметричной (асимметрия имеет смысл)\n\nКогда использовать: анализ чистых шаблонов путаницы без влияния частот и смещений.\n\nМатематически: ищет масштабирования r и c, такие что diag(r) × Original × diag(c) — дважды стохастическая.',
        sumNorm: 'Нормализация по общей сумме — совместное распределение.\n\nИнтерпретация:\n• [i,j] = P(Истинный=i И Предсказан=j)\n• Сумма всех ячеек = 1.0\n• Диагональ = P(верная классификация)\n• Вне диагонали = P(конкретные типы ошибок)\n• Сохраняет информацию о частотах классов\n\nКогда использовать: изучение общей структуры вероятностей исходов классификации.\n\nПример: [Кот, Пёс] = 0.05 — 5% всех классификаций это «коты как псы».',
        priorNorm: 'Нормализация по априори: нормализация по истине (строки), умноженная на априорные частоты.\n\nИнтерпретация:\n• Шаг 1: Нормализация по строкам создаёт P(Предсказан | Истинный)\n• Шаг 2: Каждая строка умножена на соответствующую априорную частоту P(Истинный=i)\n• Результат: P(Предсказан | Истинный) × P(Истинный) = P(Предсказан И Истинный) с указанными априори\n• Строки суммируются к априорным частотам (не к 1.0)\n• Столбцы суммируются к P(Предсказан) при указанных априори\n\nКогда использовать: нужно видеть матрицу ошибок при конкретных предположениях о распределении классов или анализировать производительность классификатора с пользовательскими частотами классов.\n\nБайесовская интерпретация: показывает совместное распределение P(Истинный, Предсказан) при указанном априори P(Истинный).',
        priorThenColumnNorm: 'Априори затем предсказание: нормализация по истине (строки), умноженная на априорные частоты, затем нормализация по столбцам.\n\nИнтерпретация:\n• Шаг 1: Нормализация по строкам создаёт P(Предсказан | Истинный)\n• Шаг 2: Каждая строка умножена на соответствующую априорную частоту P(Истинный=i)\n• Шаг 3: Нормализация по столбцам создаёт апостериорные вероятности P(Истинный | Предсказан) при указанном априори\n• Столбцы суммируются к 1.0 (апостериорные распределения вероятностей)\n• Строки не суммируются к 1.0 (балансируются указанным априори)\n• Соответствует байесовскому выводу с пользовательскими априорными вероятностями классов\n\nКогда использовать: нужны апостериорные вероятности при указанном распределении классов, устранение влияния исходной частоты классов или анализ выходов классификатора при пользовательских априори.\n\nБайесовская интерпретация: переводит выходы классификатора в апостериорные вероятности при совпадении P(Истинный класс) с указанными априори.',
        smoothingToggle: 'Аддитивное сглаживание (Лапласа) добавляет псевдосчёты, чтобы избежать нулевых вероятностей и улучшить оценки:\n\n• Необходимо для эпистемологически корректной оценки вероятностей\n• Избегает деления на ноль в вероятностных расчётах\n• Даёт более устойчивые оценки\n• Важно для корректного расчёта взаимной информации\n• Рекомендуется при разреженных матрицах\n\nПараметр α управляет силой сглаживания.',
        alphaParam: 'Параметр α (псевдосчёты в каждую ячейку):\n\nα = 0.5 (априори Джеффриза — РЕКОМЕНДУЕТСЯ):\n• Неинформативный байесовский априор для Дирихле\n• Инвариантен к масштабу и преобразованиям\n• Минимальное смещение при обработке нулей\n• Теоретически оптимален при неизвестном распределении\n\nα = 1.0 (правило Лапласа):\n• Равномерное априори (все исходы равновероятны)\n• Классический подход, легко интерпретируется\n• Хорош при отсутствии априорных знаний\n• Ровно 1 псевдосчёт в каждую ячейку\n\nα = 0 (без сглаживания):\n• Используются исходные счёты\n• Возможны проблемы с нулями\n\nБольше α = сильнее сглаживание = более консервативные оценки',
        smoothingTypeUniform: 'Равномерное',
        smoothingTypeHierarchical: 'Иерархическое',
        hierarchicalSmoothing: 'Иерархическое сглаживание с учётом априори:\n\nПсевдосчёт[i,j] = k × prior_π_i × prediction_π_j\n\n• Структурированные псевдосчёты на основе маргиналов\n• Представляет априорное убеждение, что классификатор неинформативен\n• Больше псевдосчётов для частых пар классов\n• Меньше псевдосчётов для редких пар\n• k управляет общей массой псевдосчётов\n\nСтатистическая интерпретация: априори — модель независимости (предсказания независимы от истины).',
        kParam: 'Параметр k (общая масса псевдосчётов):\n\nk = 0.5 (РЕКОМЕНДУЕТСЯ):\n• Аналогично априори Джеффриза по общей массе\n• Распределяется по маргиналам\n\nБольше k = сильнее априори в сторону модели независимости',
        rasTitle: 'Декомпозиция RAS (масштабирование строк и столбцов)',
        rasTooltip: 'Декомпозиция RAS: DoublyStochastic = diag(r) × Original × diag(c)',
        rowScalingFactors: 'Коэффициенты масштабирования строк (r)',
        columnScalingFactors: 'Коэффициенты масштабирования столбцов (c)',
        reconstructionFormula: 'Восстановление: Original[i,j] = DoublyStochastic[i,j] / (r[i] × c[j])',
        reconstructionTooltip: 'Для восстановления исходной матрицы: разделить дважды стохастическую матрицу на r[i] и c[j]',
        answerInfo: 'Количество информации, которую даёт ответ классификатора (в битах). Больше — информативнее; 0 бит — нет информации.',
        answerInfoMethod: 'Метод вычисления:\nДля каждого предсказанного класса j:\nI(True; Predicted=j) = ∑ P(True=i | Predicted=j) × log₂( P(True=i | Predicted=j) / P(True=i) )\nЗдесь P(True=i) — априорные вероятности (строковые маргиналы), оценённые по матрице ошибок (с учётом сглаживания, если включено). Единицы измерения: биты.',
        answerInfoMaxMethod: 'Метод вычисления максимума:\nI_max = max_Q D_KL(Q || P(True)) = log₂(1 / min_i P(True=i)).\nP(True) берётся из строковых маргиналов (с учётом сглаживания, если включено). Если есть нулевые априори, I_max = ∞.',
        answerInfoMaxPrefix: 'Теоретический максимум: ',
        maxShortPrefix: 'макс: ',
        bitsWord: 'бит'
      }
    }
  }
};
